{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxTTCko1/lv/gTMBLcXNZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tannisthamaiti/Market-Analytics/blob/main/moviepy_use_cases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install moviepy"
      ],
      "metadata": {
        "id": "RB3f3OLtVp2E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JFE_sumVNpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f3053e-c934-4730-c0d8-829f8666bd51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Python Code to Trim the Video\n",
        "\n",
        "Hereâ€™s a simple script to trim a video. You will need to specify the path to the source video file and define the start and end times for the clip you want to extract."
      ],
      "metadata": {
        "id": "r2-KL2KfVtCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def trim_video(video_path, start_time, end_time, output_path):\n",
        "    # Load the video file\n",
        "    video = VideoFileClip(video_path)\n",
        "\n",
        "    # Trim the video\n",
        "    trimmed_video = video.subclip(start_time, end_time)\n",
        "\n",
        "    # Write the trimmed video to a new file\n",
        "    trimmed_video.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
        "\n",
        "# Example usage\n",
        "video_path = '/content/extracted_audio.wav'\n",
        "start_time = 13  # Start at 10 seconds\n",
        "end_time = 54     # End at 20 seconds\n",
        "output_path = 'trimmed_audio.wav'\n",
        "\n",
        "trim_video(video_path, start_time, end_time, output_path)\n"
      ],
      "metadata": {
        "id": "pkaK233sV-aT",
        "outputId": "3f2c363b-a9ff-4f59-a4a6-b54f340304d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'video_fps'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0451ca97f99d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'trimmed_audio.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrim_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-0451ca97f99d>\u001b[0m in \u001b[0;36mtrim_video\u001b[0;34m(video_path, start_time, end_time, output_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrim_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Load the video file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Trim the video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/moviepy/video/io/VideoFileClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Make a reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mpix_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rgba\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_mask\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"rgb24\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         self.reader = FFMPEG_VideoReader(filename, pix_fmt=pix_fmt,\n\u001b[0m\u001b[1;32m     89\u001b[0m                                          \u001b[0mtarget_resolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_resolution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                                          \u001b[0mresize_algo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresize_algorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[1;32m     35\u001b[0m         infos = ffmpeg_parse_infos(filename, print_infos, check_duration,\n\u001b[1;32m     36\u001b[0m                                    fps_source)\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_fps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_rotation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'video_fps'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Python Code to Trim the Audio"
      ],
      "metadata": {
        "id": "yffcEgTcdKM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "\n",
        "# Load video\n",
        "video = VideoFileClip(\"/content/output1.mp4\")\n",
        "\n",
        "# Define the parts you want to keep\n",
        "part1 = video.subclip(0, 868)        # From 0s to 60s (before the cut)\n",
        "part2 = video.subclip(1017, video.duration)  # From 90s to end (after the cut)\n",
        "\n",
        "# Merge the remaining parts\n",
        "final_video = concatenate_videoclips([part1, part2])\n",
        "\n",
        "# Export\n",
        "final_video.write_videofile(\"output.mp4\", codec=\"libx264\")\n"
      ],
      "metadata": {
        "id": "OdHXC4kQ_KrL",
        "outputId": "6f2fbf09-7ee0-44c8-b5ef-84fbedba2b33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video output.mp4.\n",
            "MoviePy - Writing audio in outputTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15201/15201 [12:41<00:00, 22.65it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/output1.mp4, 6220800 bytes wanted but 0 bytes read,at frame 17584/17585, at time 1099.00/1099.02 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 :Use the following script to merge two videos:"
      ],
      "metadata": {
        "id": "oDx1GeOwWr2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "\n",
        "def merge_videos(video1_path, video2_path, output_path):\n",
        "    \"\"\"\n",
        "    Merges two videos together sequentially and saves the output.\n",
        "\n",
        "    Parameters:\n",
        "        video1_path (str): Path to the first video.\n",
        "        video2_path (str): Path to the second video.\n",
        "        output_path (str): Path to save the merged video.\n",
        "    \"\"\"\n",
        "    # Load the video clips\n",
        "    clip1 = VideoFileClip(video1_path)\n",
        "    clip2 = VideoFileClip(video2_path)\n",
        "\n",
        "    # Concatenate the videos\n",
        "    final_video = concatenate_videoclips([clip1, clip2])\n",
        "\n",
        "    # Save the final merged video\n",
        "    final_video.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
        "\n",
        "# Example usage\n",
        "video1 = \"/content/trimmed_video.mp4\"  # Path to first video\n",
        "video2 = \"/content/output.mp4\"  # Path to second video\n",
        "output_video = \"merged_video.mp4\"  # Output file\n",
        "\n",
        "merge_videos(video1, video2, output_video)"
      ],
      "metadata": {
        "id": "-1jMtDOCWgAO",
        "outputId": "2b55f9e8-8c89-43b4-e9be-dbf17b3858b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video merged_video.mp4.\n",
            "MoviePy - Writing audio in merged_videoTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video merged_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready merged_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install noisereduce"
      ],
      "metadata": {
        "id": "4Ho4nFXtlXbg",
        "outputId": "8425c92d-c726-4738-941b-ac570f452933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting noisereduce\n",
            "  Downloading noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from noisereduce) (1.14.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from noisereduce) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from noisereduce) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from noisereduce) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from noisereduce) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.17.0)\n",
            "Downloading noisereduce-3.0.3-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: noisereduce\n",
            "Successfully installed noisereduce-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Load the video\n",
        "clip = VideoFileClip(\"/content/20250323_110508.mp4\")\n",
        "\n",
        "# Extract and save the audio\n",
        "clip.audio.write_audiofile(\"extracted_audio.wav\")\n",
        "import noisereduce as nr\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Load audio\n",
        "y, sr = librosa.load(\"extracted_audio.wav\", sr=None)\n",
        "\n",
        "# Apply noise reduction\n",
        "reduced_noise = nr.reduce_noise(y=y, sr=sr)\n",
        "\n",
        "# Save enhanced audio\n",
        "sf.write(\"enhanced_audio.wav\", reduced_noise, sr)\n"
      ],
      "metadata": {
        "id": "pJHrCRKRk0Wy",
        "outputId": "e52b68ff-d421-40fc-92f4-1b182ed643df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in extracted_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insert 2 videos at 22 and 36 s"
      ],
      "metadata": {
        "id": "a6flB7tFvqvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, CompositeVideoClip\n",
        "\n",
        "# Load the base video\n",
        "base = VideoFileClip(\"base_video.mp4\")\n",
        "\n",
        "# Load the clip to overlay\n",
        "insert_clip = VideoFileClip(\"insert_clip.mp4\").set_duration(2)  # Set to 2 seconds, or adjust as needed\n",
        "\n",
        "# Create two instances of the insert clip at different times\n",
        "clip_at_22s = insert_clip.set_start(22)\n",
        "clip_at_36s = insert_clip.set_start(36)\n",
        "\n",
        "# Overlay the insert clips on top of the base\n",
        "final = CompositeVideoClip([base, clip_at_22s, clip_at_36s])\n",
        "\n",
        "# Ensure the final video is long enough\n",
        "final = final.set_duration(max(base.duration, 36 + insert_clip.duration))\n",
        "\n",
        "# Write to file\n",
        "final.write_videofile(\"output_video_overlay_22s_36s.mp4\", codec=\"libx264\")\n"
      ],
      "metadata": {
        "id": "uhE-evLrvjID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To extract frames from a video between 1 and 2 seconds, you can use tools like OpenCV in Python."
      ],
      "metadata": {
        "id": "sFoAxX50azJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Input video path\n",
        "video_path = '/content/trimmed_video2.mp4'\n",
        "output_folder = 'extracted_frames'\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Open video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get frame rate\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "start_time = 1  # seconds\n",
        "end_time = 2    # seconds\n",
        "\n",
        "# Calculate start and end frames\n",
        "start_frame = int(start_time * fps)\n",
        "end_frame = int(end_time * fps)\n",
        "\n",
        "frame_num = 0\n",
        "saved_frames = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret or frame_num > end_frame:\n",
        "        break\n",
        "\n",
        "    if start_frame <= frame_num <= end_frame:\n",
        "        frame_filename = os.path.join(output_folder, f\"frame_{frame_num}.jpg\")\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "        saved_frames += 1\n",
        "\n",
        "    frame_num += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"âœ… Extracted {saved_frames} frames between {start_time}s and {end_time}s.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGFgvKQEr8OY",
        "outputId": "15bb1b53-7006-4b6f-edac-4a165d8362a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Extracted 31 frames between 1s and 2s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python Code to Draw a Blue Box in the Center:"
      ],
      "metadata": {
        "id": "V50LbrADsW4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Create a blank white image (height=500, width=500, 3 color channels)\n",
        "img = cv2.imread('/content/extracted_frames/frame_35.jpg')\n",
        "\n",
        "# Define box size\n",
        "box_width, box_height = 180, 100\n",
        "\n",
        "# Calculate top-left and bottom-right coordinates for the centered box\n",
        "center_x, center_y = img.shape[1] // 2, img.shape[0] // 2\n",
        "top_left = (center_x - box_width // 2, center_y - box_height // 2)\n",
        "bottom_right = (center_x + box_width // 2, center_y + box_height // 2)\n",
        "\n",
        "print(center_x, center_y)\n",
        "\n",
        "# Draw a blue rectangle (BGR: Blue=(255, 0, 0))\n",
        "cv2.rectangle(img, top_left, bottom_right, (255, 0, 0), thickness=-1)\n",
        "\n",
        "# Save the image\n",
        "cv2.imwrite(\"/content/extracted_frames/frame_34.jpg\", img)\n",
        "\n",
        "print(\"âœ… Image with blue box saved as 'blue_box_image.jpg'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEpJgX6rsWG8",
        "outputId": "0db30b80-6842-446f-9600-f43af389a3fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360 640\n",
            "âœ… Image with blue box saved as 'blue_box_image.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simple-lama-inpainting opencv-python tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSAD12_5uRfP",
        "outputId": "86fba031-7055-4bb7-dcab-78a34a00e76f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: simple-lama-inpainting in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: fire<0.6.0,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from simple-lama-inpainting) (0.5.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from simple-lama-inpainting) (1.26.4)\n",
            "Requirement already satisfied: pillow<10.0.0,>=9.5.0 in /usr/local/lib/python3.11/dist-packages (from simple-lama-inpainting) (9.5.0)\n",
            "Requirement already satisfied: torch!=2.0.1,>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from simple-lama-inpainting) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from simple-lama-inpainting) (0.21.0+cu124)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from fire<0.6.0,>=0.5.0->simple-lama-inpainting) (1.17.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire<0.6.0,>=0.5.0->simple-lama-inpainting) (2.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch!=2.0.1,>=1.13.1->simple-lama-inpainting) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from simple_lama_inpainting import SimpleLama\n",
        "\n",
        "# --- Config ---\n",
        "video_path = \"/content/trimmed_video2.mp4\"  # replace with your video file\n",
        "wm_width = 180            # watermark width (adjust based on size)\n",
        "wm_height = 100            # watermark height\n",
        "output_video_path = \"clean_video.mp4\"\n",
        "\n",
        "# Create folders\n",
        "os.makedirs(\"frames\", exist_ok=True)\n",
        "os.makedirs(\"masks\", exist_ok=True)\n",
        "os.makedirs(\"inpainted\", exist_ok=True)\n",
        "\n",
        "# --- Step 1: Extract video info and frames ---\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "print(f\"Video: {width}x{height} @ {fps}fps, {frame_count} frames\")\n",
        "\n",
        "print(\"ðŸŽž Extracting frames...\")\n",
        "for i in tqdm(range(frame_count)):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    cv2.imwrite(f\"frames/frame_{i:04d}.png\", frame)\n",
        "cap.release()\n",
        "\n",
        "# --- Step 2: Create centered mask ---\n",
        "x1 = (width - wm_width) // 2\n",
        "y1 = (height - wm_height) // 2\n",
        "x2 = x1 + wm_width\n",
        "y2 = y1 + wm_height\n",
        "\n",
        "print(\"ðŸŽ­ Creating masks...\")\n",
        "for i in range(frame_count):\n",
        "    mask = Image.new(\"L\", (width, height), 0)\n",
        "    for x in range(x1, x2):\n",
        "        for y in range(y1, y2):\n",
        "            mask.putpixel((x, y), 255)\n",
        "    mask.save(f\"masks/mask_{i:04d}.png\")\n",
        "\n",
        "# --- Step 3: Inpaint using LaMa ---\n",
        "print(\"ðŸ§  Inpainting frames with LaMa...\")\n",
        "lama = SimpleLama()\n",
        "\n",
        "for i in tqdm(range(frame_count)):\n",
        "    img = Image.open(f\"frames/frame_{i:04d}.png\")\n",
        "    mask = Image.open(f\"masks/mask_{i:04d}.png\")\n",
        "    result = lama(img, mask)\n",
        "    result.save(f\"inpainted/inpainted_{i:04d}.png\")\n",
        "\n",
        "# --- Step 4: Rebuild video ---\n",
        "print(\"ðŸŽ¬ Rebuilding video...\")\n",
        "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "for i in tqdm(range(frame_count)):\n",
        "    frame = cv2.imread(f\"inpainted/inpainted_{i:04d}.png\")\n",
        "    out.write(frame)\n",
        "out.release()\n",
        "\n",
        "print(f\"âœ… Done! Watermark removed video saved as: {output_video_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23CLOOo-uYN4",
        "outputId": "0243eec6-ea8b-4476-e878-2fe33953b88c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video: 720x1280 @ 30.0fps, 300 frames\n",
            "ðŸŽž Extracting frames...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:14<00:00, 21.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ­ Creating masks...\n",
            "ðŸ§  Inpainting frames with LaMa...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [3:02:19<00:00, 36.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¬ Rebuilding video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:11<00:00, 25.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Done! Watermark removed video saved as: clean_video.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGzTHJJUCPY"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEqbX8OhE8y9"
      },
      "source": [
        "# Gemini: An Overview of Multimodal Use Cases\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fintro_multimodal_use_cases.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HKLOuOlJutv"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Saeed Aghabozorgi](https://github.com/saeedaghabozorgi) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNAByMC82jWD",
        "outputId": "3ac958d3-36be-486e-d084-13801d4a7d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.73.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (4.25.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.13.1)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.9.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade google-cloud-aiplatform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIv-VM5pnQ2G",
        "outputId": "dab37abe-d162-4471-92d2-931465a6e050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYBvd4Zyn4Uc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3j53EFvOdg3"
      },
      "source": [
        "## Connect to MongoDB\n",
        "\n",
        "DataBase : LiveAI\n",
        "<br>\n",
        "Collection: Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n3nXMO5OZAG",
        "outputId": "e79e19b4-ba66-4db4-82ea-37692d12da93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.10/dist-packages (4.10.1)\n",
            "\u001b[33mWARNING: pymongo 4.10.1 does not provide the extra 'srv'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo[srv]) (2.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"pymongo[srv]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vkyz6TrsvSU",
        "outputId": "c43a649f-eddd-4f9b-b293-4a6a6027f747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx_zRKNAst0U"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQQerLzncHUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb8ddfd-6af7-4705-c5b3-36ceb5aaba92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Password: Irammad%40123\n",
            "Connection URI: mongodb+srv://tanniTest:Irammad%40123@cluster0.2nnvu.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\n",
            "Pinged your deployment. You successfully connected to MongoDB!\n"
          ]
        }
      ],
      "source": [
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "from urllib.parse import quote_plus\n",
        "\n",
        "# Username and password\n",
        "username = \"tanniTest\"\n",
        "password = \"Irammad@123\"\n",
        "\n",
        "# Encode the password\n",
        "encoded_password = quote_plus(password)\n",
        "print(\"Encoded Password:\", encoded_password)\n",
        "\n",
        "uri = f\"mongodb+srv://{username}:{encoded_password}@cluster0.2nnvu.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "print(\"Connection URI:\", uri)\n",
        "\n",
        "\n",
        "# Create a new client and connect to the server\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "# Send a ping to confirm a successful connection\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR_d02rkgBhJ"
      },
      "outputs": [],
      "source": [
        "# Create a new database and collection\n",
        "#db = client[\"LiveAI\"]  # Replace with your desired database name\n",
        "#collection = db[\"Video\"]  # Replace with your desired collection name\n",
        "\n",
        "#print(\"Database and collection created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK1Q5ZYdVL4Y"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this notebook, you will explore a variety of different use cases enabled by multimodality with Gemini 1.5 Flash.\n",
        "\n",
        "### Gemini\n",
        "\n",
        "Gemini is a family of generative AI models developed by Google DeepMind that is designed for multimodal use cases. The Gemini API gives you access to the Gemini 1.0 Pro Vision, Gemini 1.0 Pro, Gemini 1.5 Pro and Gemini 1.5 Flash models.\n",
        "\n",
        "### Gemini API in Vertex AI\n",
        "\n",
        "The Gemini API in Vertex AI provides a unified interface for interacting with Gemini models. There are currently four models available in the Gemini API:\n",
        "\n",
        "- **Gemini 1.0 Pro model** (`gemini-1.0-pro`): Designed to handle natural language tasks, multiturn text and code chat, and code generation.\n",
        "- **Gemini 1.0 Pro Vision model** (`gemini-1.0-pro-vision`): Supports multimodal prompts. You can include text, images, and video in your prompt requests and get text or code responses.\n",
        "- **Gemini 1.5 Pro model** (`gemini-1.5-pro`): A foundation model that performs well at a variety of multimodal tasks such as visual understanding, classification, summarization, and creating content from image, audio and video..\n",
        "- **Gemini 1.5 Flash model** (`gemini-1.5-flash`): A purpose-built multimodal model that provides speed and efficiency for high-volume, quality, cost-effective apps.\n",
        "\n",
        "For more information, see the [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview) documentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQT500QqVPIb"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "This notebook demonstrates a variety of multimodal use cases that Gemini can be used for.\n",
        "\n",
        "#### Multimodal use cases\n",
        "\n",
        "Compared to text-only LLMs, Gemini 1.5's multimodality can be used for many new use-cases:\n",
        "\n",
        "Example use cases with **text and image(s)** as input:\n",
        "\n",
        "- Detecting objects in photos\n",
        "- Understanding screens and interfaces\n",
        "- Understanding of drawing and abstraction\n",
        "- Understanding charts and diagrams\n",
        "- Recommendation of images based on user preferences\n",
        "- Comparing images for similarities, anomalies, or differences\n",
        "\n",
        "Example use cases with **text and video** as input:\n",
        "\n",
        "- Generating a video description\n",
        "- Extracting tags of objects throughout a video\n",
        "- Extracting highlights/messaging of a video\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhsUe0fyc-ER"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "- Vertex AI\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDU0XJ1xRDlL"
      },
      "source": [
        "## Getting Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5afkyDMSBW5"
      },
      "source": [
        "### Install Vertex AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc4WxYmLSBW5"
      },
      "outputs": [],
      "source": [
        "#%pip install --upgrade --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fom0ZkMSBW6"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCaCx6PLSBW6"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iWrGloLbk1s"
      },
      "source": [
        "## connect with SQLLite DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZUz1Vhgbhwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6431c5f0-784b-46d0-ad8a-eeb926faf243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database created at /content/drive/MyDrive/Colab Notebooks/video_data.db with table 'videos'.\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import os\n",
        "from moviepy.editor import VideoFileClip  # Install moviepy if not already installed: pip install moviepy\n",
        "\n",
        "# Function to convert video format (optional)\n",
        "def convert_video(input_path, output_path, codec=\"libx264\"):\n",
        "    try:\n",
        "        clip = VideoFileClip(input_path)\n",
        "        clip.write_videofile(output_path, codec=codec)\n",
        "        print(f\"Video converted and saved to {output_path}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Video conversion failed: {e}\")\n",
        "\n",
        "# Function to read raw bytes from a video file\n",
        "def read_video_file(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            raw_bytes = file.read()\n",
        "            print(f\"Read {len(raw_bytes)} bytes from {file_path}.\")\n",
        "            return raw_bytes\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading video file: {e}\")\n",
        "        return None\n",
        "\n",
        "# SQLite database setup\n",
        "db_name = \"video_data.db\"  # Change as needed\n",
        "db_path = os.path.abspath(db_name)\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create a table for storing videos as BLOBs\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS videos (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    type TEXT NOT NULL,\n",
        "    data BLOB DEFAULT NULL ,\n",
        "    metadata TEXT DEFAULT NULL, -- Optional metadata field\n",
        "    description TEXT DEFAULT NULL\n",
        ");\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "print(f\"Database created at {db_path} with table 'videos'.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGB8Txa_e4V0"
      },
      "source": [
        "### Define Google Cloud project information and initialize Vertex AI\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGOJHtgDe5-r"
      },
      "outputs": [],
      "source": [
        "# Define project information\n",
        "PROJECT_ID = \"gen-lang-client-0676335328\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuQwwRiniVFG"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTk488WDPBtQ"
      },
      "outputs": [],
      "source": [
        "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image, Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7rZuTClfNs0"
      },
      "source": [
        "## Use the Gemini 1.5 Flash model\n",
        "\n",
        "Gemini 1.5 Flash (`gemini-1.5-flash`) is a multimodal model that supports multimodal prompts. You can include text, image(s), and video in your prompt requests and get text or code responses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTNnM-lqfQRo"
      },
      "source": [
        "### Load Gemini 1.5 Flash model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2998506fe6d1"
      },
      "outputs": [],
      "source": [
        "multimodal_model = GenerativeModel(\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpL3OkSCfIAR"
      },
      "source": [
        "### Define helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7QMAHXse339"
      },
      "outputs": [],
      "source": [
        "import http.client\n",
        "import typing\n",
        "import urllib.request\n",
        "\n",
        "import IPython.display\n",
        "from PIL import Image as PIL_Image\n",
        "from PIL import ImageOps as PIL_ImageOps\n",
        "\n",
        "\n",
        "def display_images(\n",
        "    images: typing.Iterable[Image],\n",
        "    max_width: int = 600,\n",
        "    max_height: int = 350,\n",
        ") -> None:\n",
        "    for image in images:\n",
        "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
        "        if pil_image.mode != \"RGB\":\n",
        "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
        "            pil_image = pil_image.convert(\"RGB\")\n",
        "        image_width, image_height = pil_image.size\n",
        "        if max_width < image_width or max_height < image_height:\n",
        "            # Resize to display a smaller notebook image\n",
        "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
        "        IPython.display.display(pil_image)\n",
        "\n",
        "\n",
        "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
        "    with urllib.request.urlopen(image_url) as response:\n",
        "        response = typing.cast(http.client.HTTPResponse, response)\n",
        "        image_bytes = response.read()\n",
        "    return image_bytes\n",
        "\n",
        "\n",
        "def load_image_from_url(image_url: str) -> Image:\n",
        "    image_bytes = get_image_bytes_from_url(image_url)\n",
        "    return Image.from_bytes(image_bytes)\n",
        "\n",
        "\n",
        "def display_content_as_image(content: str | Image | Part) -> bool:\n",
        "    if not isinstance(content, Image):\n",
        "        return False\n",
        "    display_images([content])\n",
        "    return True\n",
        "\n",
        "\n",
        "def display_content_as_video(content: str | Image | Part) -> bool:\n",
        "    if not isinstance(content, Part):\n",
        "        return False\n",
        "    part = typing.cast(Part, content)\n",
        "    file_path = part.file_data.file_uri.removeprefix(\"gs://\")\n",
        "    video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
        "    IPython.display.display(IPython.display.Video(video_url, width=600))\n",
        "    return True\n",
        "\n",
        "\n",
        "def print_multimodal_prompt(contents: list[str | Image | Part]):\n",
        "    \"\"\"\n",
        "    Given contents that would be sent to Gemini,\n",
        "    output the full multimodal prompt for ease of readability.\n",
        "    \"\"\"\n",
        "    for content in contents:\n",
        "        if display_content_as_image(content):\n",
        "            continue\n",
        "        if display_content_as_video(content):\n",
        "            continue\n",
        "        print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN8nVlITK5kz"
      },
      "source": [
        "## Generating a video description\n",
        "\n",
        "Gemini can also extract tags throughout a video:\n",
        "\n",
        "> Video: https://storage.googleapis.com/github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vPkd669nm5H"
      },
      "outputs": [],
      "source": [
        "def generate_text_from_stream(contents, multimodal_model):\n",
        "    \"\"\"\n",
        "    Converts the streamed response from multimodal_model.generate_content into a UTF-8 string.\n",
        "\n",
        "    Args:\n",
        "        contents (list): The input content (e.g., video or prompt) to pass to the model.\n",
        "        multimodal_model (GenerativeModel): The initialized multimodal model.\n",
        "\n",
        "    Returns:\n",
        "        str: The concatenated UTF-8 text from the stream.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Call the model's generate_content with stream=True\n",
        "        responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "        # Iterate through the generator and collect text responses\n",
        "        text_output = []\n",
        "        for response in responses:\n",
        "            if hasattr(response, \"text\"):\n",
        "                text_output.append(response.text)\n",
        "\n",
        "        # Concatenate the text responses\n",
        "        full_text = \"\".join(text_output)\n",
        "\n",
        "        # Ensure the result is UTF-8 encoded\n",
        "        return full_text.encode(\"utf-8\").decode(\"utf-8\")\n",
        "\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error converting stream to text: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3RurhkjrF3f"
      },
      "outputs": [],
      "source": [
        "#db = client[\"LiveAI\"]\n",
        "#collection = db[\"Video\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCLXZGjl2yKm"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, SafetySetting\n",
        "\n",
        "\n",
        "def generate():\n",
        "    vertexai.init(project=\"gen-lang-client-0676335328\", location=\"us-central1\")\n",
        "    model = GenerativeModel(\n",
        "        \"gemini-1.5-flash-002\",\n",
        "    )\n",
        "    responses = model.generate_content(\n",
        "        [\"\"\"Transcribe the video\"\"\", video1],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=True,\n",
        "    )\n",
        "    text_output = []\n",
        "    for response in responses:\n",
        "        if hasattr(response, \"text\"):\n",
        "            text_output.append(response.text)\n",
        "    for response in responses:\n",
        "        print(response.text, end=\"\")\n",
        "\n",
        "        # Concatenate the text responses\n",
        "    full_text = \"\".join(text_output)\n",
        "    return full_text.encode(\"utf-8\").decode(\"utf-8\")\n",
        "\n",
        "\n",
        "video1 = Part.from_uri(\n",
        "    mime_type=\"video/mp4\",\n",
        "    uri=\"gs://liveai/W1D1.mp4\",\n",
        ")\n",
        "\n",
        "generation_config = {\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "]\n",
        "\n",
        "generated_text=generate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "hZYBVt6f9pGA",
        "outputId": "95074052-e1bc-4000-a1fb-d27be9294230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Welcome back. So we are in this uh lecture. We're gonna be talking about a few foundational stones of machine learning and deep learning. And we're gonna start obviously with the king of deep learning today. That is obviously not TensorFlow or PyTorch, but it is your friend Python. So I am Terry, obviously and as uh you can imagine, I'm super excited to have you in in the class. Um let's sort of um take a high level view of what Python is and what it can do. So Python has become a very, very popular library. Um especially uh you know, this is a few years old, but uh the whole idea is to kind of see how Python has become so popular as a language. You can see here already Python kind of, you know, taking the cake and and moving ahead uh in this field. So it's it's a very popular library uh that has made machine learning and deep learning very, very exciting field for all of us. What else is out there? Let's take a look. So it has an awesome ecosystem. So that is the reason number one. So so we could say, you know, reason number one is um it has a great, great uh ecosystem. Scikit-Learn for example is um used for handling basic machine learning algorithms. Um so it's used for handling machine learning algorithms, uh algorithms like clustering, linear and logistics regression. So you have regression, uh you can do classification and a lot more. And then you have Pandas. Pandas is uh uh basically a short uh shortened version of panel data sets. So basically panel data set or data frame. Um and these are high level data structures uh and analysis. If you want to do high level data structure and analysis, Pandas will be your friend. Um it allows you to merge and filter data as well as uh gathering from other uh external resources. For example, you could use CSV file, Excel file, a lot more. Keras, um these days obviously Keras is part of TensorFlow. So Keras is now really a part of TensorFlow. Uh but initially Keras really popularized uh the field of deep learning as well. It allows you to do really fast calculations. So it is essentially a wrapper. It is a wrapper and it allows you to do fast uh computation uh and calculation prototyping, basically using uh GPUs uh together with your uh CPUs. Then you have these two guys and as I mentioned before as well, uh you also have mx net and a bunch of other platforms or architectures as one would say. Um TensorFlow is working. So TensorFlow, PyTorch and a few of these frameworks are really exciting to set up, train and utilize artificial neural networks for these massive data sets. And then we are going to be covering in high level also Matplotlib uh for creating 2D plots, histograms and a lot of things, 2D plots, these days even you have 3D plots, 2D plots, histograms, charts and lots of other visualizations. Great. And then you have NLP library as well, like NLTK, NLTK for working with computational linguistics. So computational linguistics. Um natural language recognition. So the whole all this NL and I just call it NLX tasks and they have become super popular in that. And there's a lot. I mean this this is really, really expanding field. I'm just covering up a few of those important things. So that is the great advantage.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ZTmPEO-C_oe1",
        "outputId": "54a8274f-12e5-4378-fba1-84fcc2b47376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Welcome back. So we are in this uh lecture. We're gonna be talking about a few foundational stones of machine learning and deep learning. And we're gonna start obviously with the king of deep learning today. That is obviously not TensorFlow or PyTorch, but it is your friend Python. So I am Terry, obviously and as uh you can imagine, I'm super excited to have you in in the class. Um let's sort of um take a high level view of what Python is and what it can do. So Python has become a very, very popular library. Um especially uh you know, this is a few years old, but uh the whole idea is to kind of see how Python has become so popular as a language. You can see here already Python kind of, you know, taking the cake and and moving ahead uh in this field. So it's it's a very popular library uh that has made machine learning and deep learning very, very exciting field for all of us. What else is out there? Let's take a look. So it has an awesome ecosystem. So that is the reason number one. So so we could say, you know, reason number one is um it has a great, great uh ecosystem. Scikit-Learn for example is um used for handling basic machine learning algorithms. Um so it's used for handling machine learning algorithms, uh algorithms like clustering, linear and logistics regression. So you have regression, uh you can do classification and a lot more. And then you have Pandas. Pandas is uh uh basically a short uh shortened version of panel data sets. So basically panel data set or data frame. Um and these are high level data structures uh and analysis. If you want to do high level data structure and analysis, Pandas will be your friend. Um it allows you to merge and filter data as well as uh gathering from other uh external resources. For example, you could use CSV file, Excel file, a lot more. Keras, um these days obviously Keras is part of TensorFlow. So Keras is now really a part of TensorFlow. Uh but initially Keras really popularized uh the field of deep learning as well. It allows you to do really fast calculations. So it is essentially a wrapper. It is a wrapper and it allows you to do fast uh computation uh and calculation prototyping, basically using uh GPUs uh together with your uh CPUs. Then you have these two guys and as I mentioned before as well, uh you also have mx net and a bunch of other platforms or architectures as one would say. Um TensorFlow is working. So TensorFlow, PyTorch and a few of these frameworks are really exciting to set up, train and utilize artificial neural networks for these massive data sets. And then we are going to be covering in high level also Matplotlib uh for creating 2D plots, histograms and a lot of things, 2D plots, these days even you have 3D plots, 2D plots, histograms, charts and lots of other visualizations. Great. And then you have NLP library as well, like NLTK, NLTK for working with computational linguistics. So computational linguistics. Um natural language recognition. So the whole all this NL and I just call it NLX tasks and they have become super popular in that. And there's a lot. I mean this this is really, really expanding field. I'm just covering up a few of those important things. So that is the great advantage.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJn44QzBd3I1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea7fa01-9d12-4bf5-8583-5d26b94b0692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MetaData from userweek1\n"
          ]
        }
      ],
      "source": [
        "metadata= input (\"MetaData from user\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "hrgm9pW1_la6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4c76f7-7974-43fe-b6db-c4f139d095e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5oKsV-kdxky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5c2457-9472-4603-b26e-8e1c791f7af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 13132450 bytes from converted_example.mp4.\n",
            "Welcome back. So we are in this uh lecture. We're gonna be talking about a few foundational stones of machine learning and deep learning. And we're gonna start obviously with the king of deep learning today. That is obviously not TensorFlow or PyTorch, but it is your friend Python. So I am Terry, obviously and as uh you can imagine, I'm super excited to have you in in the class. Um let's sort of um take a high level view of what Python is and what it can do. So Python has become a very, very popular library. Um especially uh you know, this is a few years old, but uh the whole idea is to kind of see how Python has become so popular as a language. You can see here already Python kind of, you know, taking the cake and and moving ahead uh in this field. So it's it's a very popular library uh that has made machine learning and deep learning very, very exciting field for all of us. What else is out there? Let's take a look. So it has an awesome ecosystem. So that is the reason number one. So so we could say, you know, reason number one is um it has a great, great uh ecosystem. Scikit-Learn for example is um used for handling basic machine learning algorithms. Um so it's used for handling machine learning algorithms, uh algorithms like clustering, linear and logistics regression. So you have regression, uh you can do classification and a lot more. And then you have Pandas. Pandas is uh uh basically a short uh shortened version of panel data sets. So basically panel data set or data frame. Um and these are high level data structures uh and analysis. If you want to do high level data structure and analysis, Pandas will be your friend. Um it allows you to merge and filter data as well as uh gathering from other uh external resources. For example, you could use CSV file, Excel file, a lot more. Keras, um these days obviously Keras is part of TensorFlow. So Keras is now really a part of TensorFlow. Uh but initially Keras really popularized uh the field of deep learning as well. It allows you to do really fast calculations. So it is essentially a wrapper. It is a wrapper and it allows you to do fast uh computation uh and calculation prototyping, basically using uh GPUs uh together with your uh CPUs. Then you have these two guys and as I mentioned before as well, uh you also have mx net and a bunch of other platforms or architectures as one would say. Um TensorFlow is working. So TensorFlow, PyTorch and a few of these frameworks are really exciting to set up, train and utilize artificial neural networks for these massive data sets. And then we are going to be covering in high level also Matplotlib uh for creating 2D plots, histograms and a lot of things, 2D plots, these days even you have 3D plots, 2D plots, histograms, charts and lots of other visualizations. Great. And then you have NLP library as well, like NLTK, NLTK for working with computational linguistics. So computational linguistics. Um natural language recognition. So the whole all this NL and I just call it NLX tasks and they have become super popular in that. And there's a lot. I mean this this is really, really expanding field. I'm just covering up a few of those important things. So that is the great advantage.\n",
            "Video Video saved to database.\n",
            "Video Video retrieved and saved as retrieved_example.mp4.\n",
            "Description: Welcome back. So we are in this uh lecture. We're gonna be talking about a few foundational stones of machine learning and deep learning. And we're gonna start obviously with the king of deep learning today. That is obviously not TensorFlow or PyTorch, but it is your friend Python. So I am Tarry, obviously, and as uh you can imagine, I'm super excited to have you in in the class. Um let's sort of um take a high level view of what Python is and what it can do. So Python has become a very, very popular library. Um especially, uh you know, this is a few years old, but uh the whole idea is to kinda see how Python has become so popular as a language. You can see here already Python kinda, you know, taking the cake and and moving ahead in this field. So it's it's a very popular library uh that has made machine learning and deep learning very, very exciting field for all of us. What else is out there? Let's take a look. So it has awesome ecosystem. So that is the reason number one. So so we could say, you know, reason number one is um it has a great, great uh ecosystem. Scikit-Learn, for example, is uh used for handling basic machine learning algorithms. Um so it's used for handling machine learning algorithms like clustering, linear and logistics regression. So you have regression. Uh you can do classification and a lot more. And then you have Pandas. Pandas is uh uh basically a short uh shortened version of panel datasets. So basically panel data set or data frame. Um and these are high level data structures uh and analysis. If you want to do high level data structure and analysis, Pandas will be your friend. Um it allows you to merge and filter data as well as uh gathering from other external resources. For example, you could use CSV file, Excel file, a lot more. Keras, um these days obviously Keras is part of TensorFlow. So Keras is now really a part of TensorFlow. Uh but initially Keras really popularized uh the field of deep learning. As what it allows you to do really fast calculations. So it is essentially a wrapper. It is a wrapper, and it allows you to do fast uh computation uh and calculation prototyping, basically using uh GPUs uh together with your uh CPUs. Then you have these two guys, and as I mentioned before as well, uh you also have mx net, and a bunch of other platforms or architectures as one would say. Um TensorFlow is working. So TensorFlow, PyTorch, and a few of these frameworks are really exciting to set up, train, and utilize artificial neural networks for these massive datasets. And then we are going to be covering in high level, also Matplotlib, uh for creating 2D plots, histograms, and a lot of things, 2D plots. These days even you have 3D plots, 2D plots, histograms, charts, and lots of other visualizations. Great. And then you have NLP library as well, like NLTK, NLTK for working with computational linguistics. So computational linguistics. Um natural language recognition. So the whole all this NL, I just call it NLX tasks, and they have become super popular in that. And there's a lot. I mean this this is really, really expanding field. I'm just covering up a few of those important things. So that is the great advantage.\n",
            "Welcome back. So we are in this uh lecture. We're gonna be talking about a few foundational stones of machine learning and deep learning. And we're gonna start obviously with the king of deep learning today. That is obviously not TensorFlow or PyTorch, but it is your friend Python. So I am Tarry, obviously, and as uh you can imagine, I'm super excited to have you in in the class. Um let's sort of um take a high level view of what Python is and what it can do. So Python has become a very, very popular library. Um especially, uh you know, this is a few years old, but uh the whole idea is to kinda see how Python has become so popular as a language. You can see here already Python kinda, you know, taking the cake and and moving ahead in this field. So it's it's a very popular library uh that has made machine learning and deep learning very, very exciting field for all of us. What else is out there? Let's take a look. So it has awesome ecosystem. So that is the reason number one. So so we could say, you know, reason number one is um it has a great, great uh ecosystem. Scikit-Learn, for example, is uh used for handling basic machine learning algorithms. Um so it's used for handling machine learning algorithms like clustering, linear and logistics regression. So you have regression. Uh you can do classification and a lot more. And then you have Pandas. Pandas is uh uh basically a short uh shortened version of panel datasets. So basically panel data set or data frame. Um and these are high level data structures uh and analysis. If you want to do high level data structure and analysis, Pandas will be your friend. Um it allows you to merge and filter data as well as uh gathering from other external resources. For example, you could use CSV file, Excel file, a lot more. Keras, um these days obviously Keras is part of TensorFlow. So Keras is now really a part of TensorFlow. Uh but initially Keras really popularized uh the field of deep learning. As what it allows you to do really fast calculations. So it is essentially a wrapper. It is a wrapper, and it allows you to do fast uh computation uh and calculation prototyping, basically using uh GPUs uh together with your uh CPUs. Then you have these two guys, and as I mentioned before as well, uh you also have mx net, and a bunch of other platforms or architectures as one would say. Um TensorFlow is working. So TensorFlow, PyTorch, and a few of these frameworks are really exciting to set up, train, and utilize artificial neural networks for these massive datasets. And then we are going to be covering in high level, also Matplotlib, uh for creating 2D plots, histograms, and a lot of things, 2D plots. These days even you have 3D plots, 2D plots, histograms, charts, and lots of other visualizations. Great. And then you have NLP library as well, like NLTK, NLTK for working with computational linguistics. So computational linguistics. Um natural language recognition. So the whole all this NL, I just call it NLX tasks, and they have become super popular in that. And there's a lot. I mean this this is really, really expanding field. I'm just covering up a few of those important things. So that is the great advantage.\n"
          ]
        }
      ],
      "source": [
        "# Function to save raw bytes as BLOB in the database\n",
        "def save_video_to_db(file_name, raw_data, metadata, description):\n",
        "    try:\n",
        "        cursor.execute(\n",
        "            \"\"\"\n",
        "            INSERT INTO videos (type, data, metadata, description)\n",
        "            VALUES (?, ?, ?, ?)\n",
        "            \"\"\",\n",
        "            (file_name, raw_data, metadata, description)\n",
        "        )\n",
        "        conn.commit()\n",
        "        print(description)\n",
        "        print(f\"Video {file_name} saved to database.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to save video to database: {e}\")\n",
        "\n",
        "\n",
        "def retrieve_video_from_db(file_name, output_path):\n",
        "    try:\n",
        "        # Fetch the data and description\n",
        "        cursor.execute(\n",
        "            \"SELECT data, description FROM videos WHERE type = ?\",\n",
        "            (file_name,)\n",
        "        )\n",
        "        result = cursor.fetchone()\n",
        "        if result:\n",
        "            # Write the video data to the output file\n",
        "            with open(output_path, 'wb') as file:\n",
        "                file.write(result[0])\n",
        "            print(f\"Video {file_name} retrieved and saved as {output_path}.\")\n",
        "            print(f\"Description: {result[1]}\")\n",
        "\n",
        "            # Return the description\n",
        "            return result[1]  # Return the description text\n",
        "        else:\n",
        "            print(f\"No video found with name {file_name}.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to retrieve video: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "input_video_path = \"W1D1.mov\"  # Replace with your video file path /content/W1D1.mov\n",
        "converted_video_path = \"converted_example.mp4\"\n",
        "output_video_path = \"retrieved_example.mp4\"\n",
        "\n",
        "# Optional: Convert video to a different format\n",
        "#convert_video(input_video_path, converted_video_path)\n",
        "\n",
        "# Read video file as raw bytes\n",
        "video_data = read_video_file(converted_video_path)\n",
        "\n",
        "# Save video to the database\n",
        "if video_data:\n",
        "    save_video_to_db(\"Video\", video_data, metadata,generated_text)\n",
        "\n",
        "# Retrieve video from the database\n",
        "retrieved_text=retrieve_video_from_db(\"Video\", output_video_path)\n",
        "print(retrieved_text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to add a new video entry\n",
        "def add_video_entry(type, raw_data, metadata, description):\n",
        "    try:\n",
        "        cursor.execute(\"\"\"\n",
        "        INSERT INTO videos (type, data, metadata, description)\n",
        "        VALUES (?, ?, ?, ?)\n",
        "        \"\"\", (type, raw_data, metadata, description))\n",
        "        conn.commit()\n",
        "        print(f\"New text entry '{type}' added successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to add video entry: {e}\")\n",
        "\n",
        "file_path = 'W1D5.txt'\n",
        "\n",
        "# Open the file with a specific encoding\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "\n",
        "print(content)\n",
        "# Example usage\n",
        "# Replace these values with actual data\n",
        "type_text = \"Text\"\n",
        "video_metadata = \"week1day1\"\n",
        "text_description = content\n",
        "# Simulating raw video data\n",
        "text_data = None  # Replace with actual binary data\n",
        "\n",
        "# Add the new entry\n",
        "add_video_entry(type_text, text_data, video_metadata, text_description)\n",
        "\n"
      ],
      "metadata": {
        "id": "8wMTHcdtFNFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f2abd3-ecbf-41c7-fdf9-0c400bbc0c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on your first Machine Learning problem\n",
            "\n",
            "In this end-to-end Python machine learning tutorial, you will learn how to use Scikit-Learn to build and tune a supervised learning model.\n",
            "\n",
            "The goal of this notebook is introduce you to one of the most flexible and useful libraries for Machine Learning in Python. We will skip the theory and math in this tutorial, but we will still recommend great resources for learning those. Moreover, we will give you a guideline on how to structure a ML problem given a task and a dataset.\n",
            "\n",
            "Workflow stages\n",
            "\n",
            "The notebook workflow goes through six stages:\n",
            "\n",
            "Question or problem definition;\n",
            "Acquire training and testing data;\n",
            "Wrangle, prepare, clean the data;\n",
            "Analyze, identify patterns, and explore the data;\n",
            "Model, predict and solve the problem;\n",
            "Visualize, report, and present the problem solving steps and final solution.\n",
            "\n",
            "This is a generalized approach to tackle a ML problem. However, sometimes you may want to:\n",
            "\n",
            "Combine multiple workflow stages i.e. analyzing by visualizing data;\n",
            "Perform a stage earlier than indicated: you may want to analyze data before and after wrangling;\n",
            "Perform a stage multiple times in your workflow. The visualization stage should be used as often as possible!\n",
            "Drop a stage altogether.\n",
            "Workflow goals\n",
            "\n",
            "When speaking of \"solving\" a ML problem, one should have a clear understanding of what this means. It's not a question of \"just load a bunch of data and let's classify!\". There are many other aspects to consider to build a reliable and incisive solution for the given task.\n",
            "\n",
            "If you're eager to start coding you may skip this section: it's just a collection of advices we give you in order to gain consciousness about what ML also is.\n",
            "\n",
            "Classifying\n",
            "\n",
            "We may want to classify or categorize our samples. We may also want to understand the implications or correlation of different classes with our solution goal.\n",
            "\n",
            "Correlating\n",
            "\n",
            "One can approach the problem based on available features - the data available for the problem - within the training dataset. Which features within the dataset contribute significantly to our solution goal? Statistically speaking, is there a correlation among a feature and solution goal? As the feature values change, does the solution state change as well, and vice-versa? This can be tested both for numerical and categorical features in the given dataset. We may also want to determine correlation among features for subsequent goals and workflow stages. Correlating certain features may help in creating, completing, or correcting features.\n",
            "\n",
            "Converting\n",
            "\n",
            "For the modeling stage, one needs to prepare the data. Depending on the choice of model algorithm one may require all features to be converted to their numerical equivalent value. So, for instance, converting text categorical values to numeric values.\n",
            "\n",
            "Completing\n",
            "\n",
            "Data preparation may also require us to estimate any missing values within a feature. In most cases, model algorithms work best when there are no missing values.\n",
            "\n",
            "Correcting\n",
            "\n",
            "We may also analyze the given training dataset for errors or possibly inaccurate values within features, and correct these erroneous values or exclude the samples that contain them entirely. One way to do this is to detect any outliers among our samples or features. We may also completely discard a feature if it is not contributing to the analysis or may significantly skew the results.\n",
            "\n",
            "Creating\n",
            "\n",
            "We can create new features based on an existing feature or a set of features, such that the new feature follows the correlation, conversion and completeness goals.\n",
            "\n",
            "Charting\n",
            "\n",
            "It's important to select the right visualization plots and charts depending on the nature of the data and the solution goals.\n",
            "\n",
            "This tutorial is designed to be streamlined, and it won't cover any one topic in too much detail. It may be helpful to have the Scikit-Learn documentation open beside you as a supplemental reference.\n",
            "New text entry 'Text' added successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the database connection\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "YCmZ4Rk11rG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmis8TsvjkOJ"
      },
      "outputs": [],
      "source": [
        "# # Restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}